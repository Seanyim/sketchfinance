import streamlit as st
import pandas as pd
from PIL import Image
import os
import sys
import json
import gc
from datetime import datetime

# Aggressive memory management for CUDA
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
from streamlit_paste_button import paste_image_button

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import importlib.util
from backend.app.services.ocr_service import OCRService
from backend.app.models.finance_model import init_db, SessionLocal
from backend.app.repositories.finance_repo import FinanceRepository

# Helper: Load Config
def load_financial_metrics(config_path):
    spec = importlib.util.spec_from_file_location("config", config_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module.FINANCIAL_METRICS

# Initialize database
init_db()

st.set_page_config(page_title="SketchFinance - è´¢åŠ¡æ•°æ®è¯†å½•", layout="wide")

# Sidebar - Config Only
st.sidebar.header("ğŸ“ æŒ‡æ ‡é…ç½®")
default_config_path = os.path.join(os.getcwd(), "backend", "config", "config.py")
uploaded_config = st.sidebar.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰ config.py (ä»…å½±å“æ•°æ®å½•å…¥)", type=['py'])

if uploaded_config:
    temp_config_path = "temp_config.py"
    with open(temp_config_path, "wb") as f:
        f.write(uploaded_config.getbuffer())
    FINANCIAL_METRICS = load_financial_metrics(temp_config_path)
    st.sidebar.success("å·²åŠ è½½è‡ªå®šä¹‰é…ç½®")
else:
    FINANCIAL_METRICS = load_financial_metrics(default_config_path)

# Initialize OCR Service (CPU mode for stability)
if 'ocr_service' not in st.session_state:
    st.session_state.ocr_service = OCRService(gpu=False)

# Clean memory periodically
gc.collect()

if 'db' not in st.session_state:
    st.session_state.db = SessionLocal()
    st.session_state.repo = FinanceRepository(st.session_state.db)

if 'auto_disclosure_date' not in st.session_state:
    st.session_state.auto_disclosure_date = ""

# Sidebar - Samples and History
st.sidebar.header("ğŸ“ å‚è€ƒä¸å†å²")
sample_dir = os.path.join(os.getcwd(), "samples")
if not os.path.exists(sample_dir):
    os.makedirs(sample_dir)

samples = [f for f in os.listdir(sample_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.db'))]
selected_sample = st.sidebar.selectbox("é€‰æ‹©å‚è€ƒæ–‡ä»¶", ["æ— "] + samples)

if selected_sample != "æ— ":
    st.sidebar.info(f"æ­£åœ¨æŸ¥çœ‹: {selected_sample}")

# Helper: Filter metrics by category
def get_metrics_by_category(category):
    return [m for m in FINANCIAL_METRICS if m.get('category') == category]

# Main Layout: Two columns
col_up, col_res = st.columns([1, 1])

with col_up:
    # Category & Disclosure Date
    st.header("1. é…ç½®åŸºç¡€ä¿¡æ¯")
    cats = globals().get('CATEGORY_ORDER', ["å…³é”®æŒ‡æ ‡", "åˆ©æ¶¦è¡¨", "èµ„äº§è´Ÿå€ºè¡¨", "ç°é‡‘æµé‡è¡¨"])
    selected_category = st.selectbox("è¯·é€‰æ‹©è¦è¯†åˆ«çš„æŠ¥è¡¨ç±»å‹", cats)
    current_metrics = get_metrics_by_category(selected_category)
    
    # Disclosure date will be extracted automatically
    if st.session_state.auto_disclosure_date:
        st.success(f"ğŸ“… è¯†åˆ«åˆ°æŠ¥è¡¨æˆªæ­¢æ—¥: {st.session_state.auto_disclosure_date}")

    # Multi-Image Upload
    st.header("2. ä¸Šä¼ /ç²˜è´´æˆªå›¾æ¨¡å—")
    st.info("æç¤ºï¼šæ‚¨å¯ä»¥ç›´æ¥ç‚¹å‡»æŒ‰é’®å¹¶ä½¿ç”¨ Ctrl+V ç²˜è´´æˆªå›¾")
    
    col_p, col_m, col_v = st.columns(3)
    with col_p:
        st.subheader("ğŸ“… å­£åº¦")
        upload_p = st.file_uploader("æ–‡ä»¶", type=["png", "jpg", "jpeg"], key="up_p")
        paste_p = paste_image_button("ğŸ“‹ ç²˜è´´å­£åº¦", key="p_p")
        img_p = upload_p if upload_p else (paste_p.image_data if paste_p.image_data else None)
        if img_p: st.image(img_p)
    with col_m:
        st.subheader("ğŸ“Š ç§‘ç›®")
        upload_m = st.file_uploader("æ–‡ä»¶", type=["png", "jpg", "jpeg"], key="up_m")
        paste_m = paste_image_button("ğŸ“‹ ç²˜è´´ç§‘ç›®", key="p_m")
        img_m = upload_m if upload_m else (paste_m.image_data if paste_m.image_data else None)
        if img_m: st.image(img_m)
    with col_v:
        st.subheader("ğŸ’° æ•°æ®")
        upload_v = st.file_uploader("æ–‡ä»¶", type=["png", "jpg", "jpeg"], key="up_v")
        paste_v = paste_image_button("ğŸ“‹ ç²˜è´´æ•°æ®", key="p_v")
        img_v = upload_v if upload_v else (paste_v.image_data if paste_v.image_data else None)
        if img_v: st.image(img_v)

    if st.button("ğŸš€ å¼€å§‹å¤šå›¾æ™ºèƒ½è¯†åˆ«", use_container_width=True):
        if not (img_p and img_m and img_v):
            st.warning("è¯·ä¸Šä¼ å®Œæ•´çš„ä¸‰ä¸ªéƒ¨åˆ†æˆªå›¾ã€‚")
        else:
            with st.spinner(f"æ­£åœ¨æ·±åº¦è§£æ {selected_category}..."):
                # Save temp
                paths = []
                for img, n in [(img_p, "p"), (img_m, "m"), (img_v, "v")]:
                    path = f"temp_{n}.png"
                    if hasattr(img, 'save'): # PIL Image from paste
                        img.save(path)
                    else: # Bytes/UploadedFile
                        with Image.open(img) as o_img:
                            o_img.save(path)
                    paths.append(path)
                
                gc.collect()
                
                # Perform Multi-Image OCR
                try:
                    parsed_data, extracted_date = st.session_state.ocr_service.parse_multi_image(
                        paths[0], paths[1], paths[2], current_metrics
                    )
                except Exception as e:
                    st.error(f"OCR è¯†åˆ«å¤±è´¥: {e}. å»ºè®®å…³é—­ä¾§è¾¹æ  'OCR GPU åŠ é€Ÿ' åé‡è¯•ã€‚")
                    parsed_data, extracted_date = None, None

                if extracted_date:
                    st.session_state.auto_disclosure_date = extracted_date
                
                
                if parsed_data:
                    for item in parsed_data: item['category'] = selected_category
                    df = pd.DataFrame(parsed_data)
                    df = df.drop_duplicates(subset=['metric_id', 'period'], keep='first')
                    
                    # åˆ›å»ºä¸»æ•°æ®é€è§†è¡¨
                    pivot_df = df.pivot(index='metric_id', columns='period', values='value')
                    labels_map = {m['id']: m['label'] for m in FINANCIAL_METRICS}
                    pivot_df.index = pivot_df.index.map(lambda x: labels_map.get(x, x))
                    
                    # æå–æ¯å­£åº¦çš„æˆªæ­¢æ—¥æœŸ
                    if 'report_date' in df.columns:
                        date_df = df.drop_duplicates(subset=['period'])[['period', 'report_date']]
                        date_dict = dict(zip(date_df['period'], date_df['report_date']))
                        st.session_state.period_dates = date_dict
                        
                        # åˆ›å»ºæ—¥æœŸè¡Œå¹¶æ·»åŠ åˆ°é€è§†è¡¨
                        date_row = pd.DataFrame([date_dict], index=['æˆªæ­¢æ—¥æœŸ'])
                        date_row = date_row.reindex(columns=pivot_df.columns)
                        pivot_df = pd.concat([date_row, pivot_df])
                    
                    st.session_state.parsed_df = pivot_df
                    st.session_state.raw_parsed = parsed_data
                    st.success("è¯†åˆ«å®Œæˆ!")
                else:
                    st.error("è¯†åˆ«å¤±è´¥ï¼Œè¯·æ£€æŸ¥æˆªå›¾ã€‚")


with col_res:
    st.subheader("ğŸ“‹ è¯†åˆ«ç»“æœé¢„è§ˆä¸ç¼–è¾‘")
    if 'parsed_df' in st.session_state:
        # æ˜¾ç¤ºæŠ«éœ²æ—¥æœŸ
        if st.session_state.auto_disclosure_date:
            st.info(f"ğŸ“… è¯†åˆ«åˆ°çš„æŠ«éœ²æ—¥æœŸï¼š**{st.session_state.auto_disclosure_date}**")
        
        edited_df = st.data_editor(st.session_state.parsed_df, use_container_width=True)
        
        target_ticker = st.text_input("å…¬å¸ä»£ç  (Ticker)", value="NVDA")
        
        # æ•°æ®åº“ç®¡ç†é€‰é¡¹
        db_col1, db_col2 = st.columns(2)
        with db_col1:
            overwrite_existing = st.checkbox("ğŸ”„ è¦†ç›–ç›¸åŒæ—¥æœŸæ•°æ®", value=True, 
                help="å‹¾é€‰åï¼Œç›¸åŒTickerã€å¹´ä»½ã€æœŸé—´ã€ç±»åˆ«çš„æ•°æ®ä¼šè¢«è¦†ç›–ï¼›å¦åˆ™è·³è¿‡å·²å­˜åœ¨çš„è®°å½•")
        with db_col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºè¯¥ç±»åˆ«æ•°æ®"):
                # è·å–å°†è¢«åˆ é™¤çš„è®°å½•æ•°
                deleted = st.session_state.repo.delete_by_category(selected_category)
                st.warning(f"å·²æ¸…ç©º {deleted} æ¡{selected_category}æ•°æ®")
                st.rerun()

        if st.button("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“ (Pivot Format)"):
            try:
                # è·å–æ¯å­£åº¦æˆªæ­¢æ—¥æœŸ
                period_dates = st.session_state.get('period_dates', {})
                
                # è°ƒç”¨æ–°çš„ Pivot æ ¼å¼ä¿å­˜æ–¹æ³•
                st.session_state.repo.save_pivot_data(
                    category=selected_category,
                    ticker=target_ticker,
                    pivot_df=edited_df,
                    period_dates=period_dates
                )
                
                st.success(f"å·²æˆåŠŸä¿å­˜ {selected_category} æ•°æ®åˆ°æ•°æ®åº“ï¼")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    else:
        st.info('å°šæœªè¿›è¡Œè¯†åˆ«ã€‚è¯·å…ˆä¸Šä¼ æˆ–ç²˜è´´æˆªå›¾å¹¶ç‚¹å‡»å¼€å§‹è¯†åˆ«ã€‚')

# History View (Pivot Format - Per Category)
st.divider()
st.header("ğŸ“Š æ•°æ®åº“å·²å½•å…¥æ•°æ®")

# æŒ‰ç±»åˆ«æ˜¾ç¤ºæ•°æ®
from backend.app.models.finance_model import CATEGORY_MODEL_MAP
db_categories = list(CATEGORY_MODEL_MAP.keys())
selected_db_category = st.selectbox("é€‰æ‹©è¦æŸ¥çœ‹çš„ç±»åˆ«", db_categories, key="db_view_category")

db_df = st.session_state.repo.get_pivot_data(selected_db_category)
if not db_df.empty:
    st.dataframe(db_df, use_container_width=True)
else:
    st.info(f"æš‚æ—  {selected_db_category} æ•°æ®å½•å…¥è®°å½•ã€‚")

